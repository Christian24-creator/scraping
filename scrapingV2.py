import streamlit as st
import requests
import re
import json
import time

# Configurar la p√°gina de Streamlit
st.set_page_config(
    page_title="Sufarmed - Buscador de Precios",
    page_icon="üíä",
    layout="centered"
)

# T√≠tulo principal
st.title("üè• Sufarmed - Buscador de Precios")
st.markdown("---")

class SufarmedScraper:
    def __init__(self):
        self.session = requests.Session()
        # Headers para simular un navegador real
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
    
    def extract_csrf_token(self, html_content):
        """Extrae token CSRF del HTML usando regex"""
        patterns = [
            r'name="token"\s+value="([^"]+)"',
            r'name="_token"\s+value="([^"]+)"',
            r'name="csrf_token"\s+value="([^"]+)"',
            r'"token":"([^"]+)"',
            r'csrf_token["\s]*:["\s]*([^"]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, html_content, re.IGNORECASE)
            if match:
                return match.group(1)
        return None
    
    def extract_form_data(self, html_content):
        """Extrae datos de formulario usando regex"""
        form_data = {}
        
        hidden_pattern = r'<input[^>]*type=["\']hidden["\'][^>]*name=["\']([^"\']+)["\'][^>]*value=["\']([^"\']*)["\'][^>]*>'
        matches = re.findall(hidden_pattern, html_content, re.IGNORECASE)
        
        for name, value in matches:
            form_data[name] = value
        
        return form_data
    
    def login(self, email, password):
        """Intenta hacer login en Sufarmed con debug mejorado"""
        try:
            login_url = "https://sufarmed.com/sufarmed/iniciar-sesion"
            response = self.session.get(login_url, timeout=15)
            
            if response.status_code != 200:
                return False, f"No se pudo acceder a la p√°gina de login (Status: {response.status_code})"
            
            if "login" not in response.text.lower() and "email" not in response.text.lower():
                return False, "La p√°gina no parece ser un formulario de login"
            
            form_data = {}
            
            hidden_patterns = [
                r'<input[^>]*type=["\']hidden["\'][^>]*name=["\']([^"\']+)["\'][^>]*value=["\']([^"\']*)["\']',
                r'<input[^>]*name=["\']([^"\']+)["\'][^>]*type=["\']hidden["\'][^>]*value=["\']([^"\']*)["\']',
                r'<input[^>]*value=["\']([^"\']*)["\'][^>]*name=["\']([^"\']+)["\'][^>]*type=["\']hidden["\']'
            ]
            
            for pattern in hidden_patterns:
                matches = re.findall(pattern, response.text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    if len(match) == 2:
                        name, value = match
                        form_data[name] = value
     
            csrf_patterns = [
                r'name=["\']token["\'][^>]*value=["\']([^"\']+)["\']',
                r'name=["\']_token["\'][^>]*value=["\']([^"\']+)["\']',
                r'name=["\']csrf_token["\'][^>]*value=["\']([^"\']+)["\']',
                r'name=["\']authenticity_token["\'][^>]*value=["\']([^"\']+)["\']',
                r'"token"[:\s]*"([^"]+)"',
                r'"_token"[:\s]*"([^"]+)"'
            ]
            
            csrf_token = None
            for pattern in csrf_patterns:
                match = re.search(pattern, response.text, re.IGNORECASE)
                if match:
                    csrf_token = match.group(1)
                    break
            
            if csrf_token:
                form_data['token'] = csrf_token
            
            possible_field_names = {
                'email': ['email', 'username', 'user', 'login_email', 'customer_email'],
                'password': ['password', 'passwd', 'pwd', 'login_password', 'customer_password'],
                'submit': ['submitLogin', 'submit', 'login', 'submit_login', '1']
            }
            
            # Aseg√∫rate de que los campos de email y password est√©n en form_data con los nombres correctos
            form_data.update({
                'email': email,
                'password': password,
                'submitLogin': '1' # Por si acaso, un nombre com√∫n para el bot√≥n de submit
            })
            
            for field_type, names in possible_field_names.items():
                for name in names:
                    if field_type == 'email':
                        form_data[name] = email
                    elif field_type == 'password':
                        form_data[name] = password
                    elif field_type == 'submit':
                        if name in response.text: # Solo si el nombre del submit button est√° en la p√°gina
                            form_data[name] = '1' 

            post_headers = {
                'Referer': login_url,
                'Origin': 'https://sufarmed.com',
                'Content-Type': 'application/x-www-form-urlencoded'
            }
            
            login_response = self.session.post(
                login_url, 
                data=form_data, 
                headers=post_headers,
                timeout=15,
                allow_redirects=True
            )
            
            final_url = login_response.url.lower()
            response_text = login_response.text.lower()
            
            success_indicators = [
                "mi-cuenta" in final_url,
                "my-account" in final_url,
                "dashboard" in final_url,
                "account" in final_url,
                "profile" in final_url,
                "bienvenido" in response_text,
                "welcome" in response_text,
                "logout" in response_text,
                "cerrar sesion" in response_text,
                "salir" in response_text
            ]
            
            error_indicators = [
                "error" in response_text and ("login" in response_text or "email" in response_text),
                "incorrect" in response_text,
                "invalid" in response_text and ("email" in response_text or "password" in response_text),
                "incorrecto" in response_text,
                "invalido" in response_text,
                "credenciales" in response_text and "incorrectas" in response_text
            ]
            
            if any(success_indicators):
                return True, "Login exitoso"
            elif any(error_indicators):
                return False, "Credenciales incorrectas o error en login"
            elif login_response.status_code == 200:
                if "login" in response_text and "password" in response_text:
                    return False, "A√∫n en p√°gina de login - posible error de credenciales"
                else:
                    return True, "Login posiblemente exitoso (verificaci√≥n ambigua)"
            else:
                return False, f"Error HTTP en login (Status: {login_response.status_code})"
                
        except requests.exceptions.Timeout:
            return False, "Timeout: El servidor tard√≥ demasiado en responder durante el login"
        except requests.exceptions.ConnectionError:
            return False, "Error de conexi√≥n durante el login"
        except Exception as e:
            return False, f"Error inesperado durante el login: {str(e)}"
    
    def extract_product_details(self, html_content):
        """
        Extrae nombres de productos y sus precios asociados del HTML.
        Busca contenedores de productos y luego extrae el nombre y el precio de cada uno.
        """
        products_data = []

        # Patr√≥n para encontrar el div contenedor de la descripci√≥n del producto
        # que t√≠picamente contiene el t√≠tulo del producto y el precio.
        # Captura todo el contenido dentro de este div.
        product_container_pattern = r'<div[^>]*class=["\'][^"\']*col-description[^"\']*["\'][^>]*>(.*?)<\/div>'
        
        container_matches = re.findall(product_container_pattern, html_content, re.IGNORECASE | re.DOTALL)
        
        for container_html in container_matches:
            name = None
            price = "No disponible" # Valor por defecto si el precio no se encuentra

            # Patr√≥n para el nombre del producto dentro del <h2>.product-title que contiene un <a>
            # Group 1: El texto del nombre del producto
            name_pattern = r'<h2[^>]*class=["\'][^"\']*product-title[^"\']*["\'][^>]*>\s*<a[^>]*>(.*?)<\/a>'
            name_match = re.search(name_pattern, container_html, re.IGNORECASE | re.DOTALL)
            if name_match:
                name = name_match.group(1).strip()
            
            # Patr√≥n para el precio que sigue inmediatamente al </a> dentro del <h2> (ej. "== $0")
            # Group 1: El valor num√©rico del precio
            price_after_name_pattern = r'<a[^>]*>.*?<\/a>\s*(?:==\s*\$?([0-9]+\.?[0-9]*))'
            price_match_after_name = re.search(price_after_name_pattern, container_html, re.IGNORECASE | re.DOTALL)
            
            if price_match_after_name and price_match_after_name.group(1):
                price = price_match_after_name.group(1).strip()
            else:
                # Si el precio no est√° inmediatamente despu√©s del nombre, buscarlo con otros patrones comunes
                # dentro del mismo contenedor de producto.
                common_price_patterns = [
                    # Busca precio en etiquetas con class="product-price" o "price"
                    r'<[^>]*class=["\'][^"\']*(?:product-price|price)[^"\']*["\'][^>]*content=["\']([^"\']+)["\']',
                    r'content=["\']([0-9]+\.?[0-9]*)["\'][^>]*class=["\'][^"\']*(?:product-price|price)',
                    r'<[^>]*class=["\'][^"\']*(?:product-price|price)[^"\']*["\'][^>]*>\s*\$?([0-9]+\.?[0-9]*)',
                    # Busca un valor num√©rico precedido por "$"
                    r'\$([0-9]+\.?[0-9]*)',
                    # Busca precio en JSON-like estructuras (ej. "price": "12.34")
                    r'["\']price["\"]\s*:\s*["\']?([0-9]+\.?[0-9]*)["\']?',
                    r'["\']precio["\"]\s*:\s*["\']?([0-9]+\.?[0-9]*)["\']?'
                ]
                
                for p_pattern in common_price_patterns:
                    price_match_other = re.search(p_pattern, container_html, re.IGNORECASE)
                    if price_match_other:
                        # Limpiar el precio (quitar $, comas)
                        found_price = str(price_match_other.group(1)).replace('$', '').replace(',', '').strip()
                        # Verificar si el precio es un n√∫mero v√°lido
                        if found_price and found_price.replace('.', '', 1).isdigit(): 
                            price = found_price
                            break # Ya encontramos un precio, no necesitamos buscar m√°s
            
            if name: # Solo a√±ade el producto a la lista si se encontr√≥ un nombre
                products_data.append({'name': name, 'price': price})
        
        return products_data

    def buscar_producto(self, producto):
        """Busca un producto y obtiene todos los nombres y precios."""
        try:
            search_urls = [
                f"https://sufarmed.com/sufarmed/buscar?s={producto}",
                f"https://sufarmed.com/sufarmed/buscar?controller=search&s={producto}",
                f"https://sufarmed.com/buscar?s={producto}"
            ]
            
            for search_url in search_urls:
                try:
                    response = self.session.get(search_url, timeout=15)
                    
                    if response.status_code == 200:
                        products_data = self.extract_product_details(response.text)
                        
                        if products_data:
                            return products_data, "Productos y precios encontrados"
                        
                        if "producto" in response.text.lower() or "product" in response.text.lower():
                            return [], "Productos encontrados pero sin precios visibles o no extra√≠bles"
                    
                except requests.exceptions.Timeout:
                    continue
                except Exception: # Captura excepciones generales para probar otras URLs
                    continue
            
            return [], "No se encontraron productos o no se pudo acceder a la b√∫squeda"
                
        except Exception as e:
            return [], f"Error durante la b√∫squeda: {str(e)}"
    
    def buscar_sin_login(self, producto):
        """Busca producto sin login como fallback y obtiene nombres y precios."""
        try:
            search_url = f"https://sufarmed.com/buscar?s={producto}"
            response = self.session.get(search_url, timeout=10)
            
            if response.status_code == 200:
                products_data = self.extract_product_details(response.text)
                if products_data:
                    return products_data, "Productos y precios encontrados (sin login)"
            
            return [], "No se encontraron resultados sin login"
            
        except Exception as e:
            return [], f"Error en b√∫squeda sin login: {str(e)}"

# Configuraci√≥n de credenciales
st.markdown("### üîê Configuraci√≥n de Cuenta")

with st.expander("Configurar Credenciales de Sufarmed", expanded=True):
    col1, col2 = st.columns(2)
    
    with col1:
        email_input = st.text_input(
            "üìß Email de Sufarmed:",
            placeholder="tu-email@ejemplo.com",
            help="Ingresa tu email registrado en Sufarmed"
        )
    
    with col2:
        password_input = st.text_input(
            "üîí Contrase√±a de Sufarmed:",
            type="password",
            placeholder="Tu contrase√±a",
            help="Ingresa tu contrase√±a de Sufarmed"
        )
    
    if not email_input or not password_input:
        st.warning("‚ö†Ô∏è Debes ingresar tu email y contrase√±a para continuar")
    else:
        st.success("‚úÖ Credenciales configuradas correctamente")

# Interfaz de usuario
st.markdown("### üîç Buscar Producto")

producto_buscar = st.text_input(
    "Ingresa el nombre del producto:",
    placeholder="Ej: Paracetamol, Ibuprofeno, etc."
)

if st.button("üîç Buscar Precio", type="primary"):
    if not email_input or not password_input:
        st.error("‚ùå Debes configurar tu email y contrase√±a primero")
    elif producto_buscar:
        with st.spinner("Buscando producto..."):
            try:
                scraper = SufarmedScraper()
                
                EMAIL = email_input
                PASSWORD = password_input
                
                products_found = []  # Ahora almacenar√° una lista de diccionarios {name, price}
                search_message = ""
                
                st.info("üîê Intentando iniciar sesi√≥n en Sufarmed...")
                login_success, login_message = scraper.login(EMAIL, PASSWORD)
                
                if login_success:
                    st.success(f"‚úÖ {login_message}")
                    
                    st.info(f"üîç Buscando: {producto_buscar}")
                    products_found, search_message = scraper.buscar_producto(producto_buscar)
                    
                else:
                    st.warning(f"‚ö†Ô∏è Login fall√≥: {login_message}")
                    st.info("üîÑ Intentando b√∫squeda sin login...")
                    products_found, search_message = scraper.buscar_sin_login(producto_buscar)
                
                if products_found:
                    st.markdown("---")
                    st.markdown("### üí∞ Resultados de la B√∫squeda")
                    
                    st.subheader(f"Productos encontrados para: {producto_buscar}")
                    for i, product_item in enumerate(products_found):
                        st.markdown(f"**{product_item['name']}**")
                        st.write(f"**Precio:** ${product_item['price']}")
                        st.markdown("---") # Separador para cada producto
                    
                    st.success("üéâ ¬°B√∫squeda completada exitosamente!")
                else:
                    st.warning(f"‚ö†Ô∏è {search_message}")
                    st.info("üí° Intenta con un nombre de producto m√°s espec√≠fico o verifica que est√© disponible en Sufarmed")
                    
            except Exception as e:
                st.error(f"‚ùå Error general: {str(e)}")
    else:
        st.warning("‚ö†Ô∏è Por favor ingresa un nombre de producto")

# Informaci√≥n adicional
st.markdown("---")
st.markdown("### ‚ÑπÔ∏è Informaci√≥n")
st.info("""
- **Paso 1**: Configura tus credenciales de Sufarmed arriba
- **Paso 2**: Ingresa el nombre del producto que deseas buscar
- **Paso 3**: Haz clic en "Buscar Precio"
- Esta aplicaci√≥n busca precios de productos en Sufarmed.com
- Utiliza requests y regex para extraer informaci√≥n (100% compatible con Streamlit Cloud)
- Intenta hacer login autom√°ticamente, pero tambi√©n funciona sin login
- Los resultados mostrados corresponden a todos los precios y nombres encontrados para la b√∫squeda
""")

# Debug/Test section
with st.expander("üîß Panel de Pruebas y Debug"):
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("Probar Conexi√≥n"):
            with st.spinner("Probando conexi√≥n..."):
                try:
                    response = requests.get("https://sufarmed.com", timeout=5)
                    st.success(f"‚úÖ Conexi√≥n exitosa - Status: {response.status_code}")
                except Exception as e:
                    st.error(f"‚ùå Error de conexi√≥n: {str(e)}")
    
    with col2:
        if st.button("Debug Login"):
            if email_input and password_input:
                with st.spinner("Analizando proceso de login..."):
                    scraper = SufarmedScraper()
                    try:
                        response = scraper.session.get("https://sufarmed.com/sufarmed/iniciar-sesion", timeout=10)
                        
                        st.write("**An√°lisis de la p√°gina de login:**")
                        st.write(f"- Status Code: {response.status_code}")
                        st.write(f"- URL Final: {response.url}")
                        
                        email_fields = re.findall(r'name=["\']([^"\']*email[^"\']*)["\']', response.text, re.IGNORECASE)
                        password_fields = re.findall(r'name=["\']([^"\']*password[^"\']*)["\']', response.text, re.IGNORECASE)
                        
                        if email_fields:
                            st.write(f"- Campos de email encontrados: {email_fields}")
                        if password_fields:
                            st.write(f"- Campos de password encontrados: {password_fields}")
                        
                        tokens = re.findall(r'name=["\']([^"\']*token[^"\']*)["\'][^>]*value=["\']([^"\']+)["\']', response.text, re.IGNORECASE)
                        if tokens:
                            st.write(f"- Tokens encontrados: {len(tokens)} tokens")
                        
                        st.success("‚úÖ An√°lisis completado")
                        
                    except Exception as e:
                        st.error(f"‚ùå Error en debug: {str(e)}")
            else:
                st.warning("Ingresa credenciales primero para hacer debug")

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>Desarrollado con Streamlit üöÄ | Sin dependencias externas</div>", 
    unsafe_allow_html=True
)
